# 조명근 AWS DEA 2주차 스터디

공부한 문제 개수: 8개

# AWS Athena

- 표준 SQL문으로 S3에 있는 데이터를 분석 할 수 있는 대화형 쿼리 서비스
- Quick Sight와 통합되어서 사용됨
- 작업그룹
  - 작업 그룹을 사용하여 워크로드를 분리하고, 팀 액세스를 제어하고, 구성을 적용하고, 쿼리 지표를 추적하여 비용을 제어할 수 있습니다.
  - **각 작업 그룹별 쿼리 실행 기록과 결과 저장을 따로 관리 가능**

# AWS Data Exchange

- AWS 데이터 마켓

# AWS Data Sync

- 다른 클라우드 혹은 온프레미스 환경에서 AWS로 데이터 소스를 이전할 때 사용하는 서비스

# AWS DMS

- AWS Database Migration Service
- **비용 효율적**: **변경된 데이터만 복제(증분 마이그레이션)** 가능 → 데이터 전송 비용 절감
- **최소한의 다운타임**: **CDC(변경 데이터 캡처)** 기능을 사용해 **운영 DB를 계속 사용하면서 실시간 데이터 동기화 가능**
- **지원 데이터베이스 다양**: Microsoft SQL Server, MySQL, PostgreSQL, Oracle 등 다양한 데이터베이스 지원
- **완전관리형 서비스**: 설정 및 운영 부담 감소

# AWS Glue

https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html

- AWS Glue는 분석, 기계 학습(ML) 및 애플리케이션 개발을 위해 여러 소스에서 데이터를 쉽게 탐색, 준비, 이동 및 통합할 수 있도록 하는 확장 가능한 서버리스 데이터 통합 서비스.
- 대량의 데이터를 변환, 통합할 때 주로 사용함. 즉 서버리스 ETL이 필요할 때 사용.
  - ETL
    - **추출(Extract), 변환(Transform), 로드(Load)**
- glue studio로 ETL 과정을 시각화 가능
- 실시간 데이터처리는 Kinesis를 사용하는게 더 좋을 수 있음.
- **✅ AWS Glue를 사용하는 주요 시나리오**
  **1️⃣ 데이터 레이크 구축 (Amazon S3 + AWS Glue)**
  • 원본 데이터를 **Amazon S3에 저장**하고, Glue로 **데이터 정제 및 변환**
  • **Glue Data Catalog**를 사용해 S3의 데이터를 자동으로 스키마화하여 **Athena, Redshift Spectrum**에서 쉽게 쿼리 가능
  • **사용 사례**: 로그 데이터 분석, 머신러닝 모델을 위한 데이터 정제
  **2️⃣ 데이터 웨어하우스 로딩 (Amazon Redshift)**
  • 다양한 데이터 소스(S3, RDS, DynamoDB)에서 데이터를 가져와 **Redshift로 적재**
  • 데이터 정제 및 변환을 AWS Glue에서 처리
  • **사용 사례**: BI(Business Intelligence) 대시보드 구축, OLAP 분석
  **3️⃣ 데이터 파이프라인 자동화**
  • AWS Glue Workflow를 사용해 **ETL 작업을 자동 실행**
  • AWS Step Functions, Lambda와 연계해 **데이터 처리 및 적재 프로세스 자동화**
  • **사용 사례**: 매일 새벽 3시에 S3 데이터 정리 후 Redshift로 적재
  **4️⃣ 이기종 데이터 통합**
  • **On-premise 데이터베이스 ↔ AWS 간 데이터 이동**
  • AWS Glue가 JDBC, DynamoDB, Kafka 등 다양한 소스를 지원하므로, 여러 시스템 간 **데이터 변환 및 통합** 가능
  • **사용 사례**: 레거시 시스템 데이터를 클라우드로 마이그레이션
  **5️⃣ 스트리밍 데이터 처리 (AWS Glue Streaming)**
  • Kinesis, Kafka에서 실시간으로 데이터를 가져와 정제 후 S3, Redshift로 저장
  • **사용 사례**: 실시간 로그 분석, IoT 데이터 처리
- glue workflow
  - glue blueprint로 워크플로를 생성할 수 있다.
- Glue Flex
  - 긴급하지 않은 데이터 통합 워크로드의 비용을 최대 35% 절감할 수 있는 실행 작업 클래스임
  - 시작 및 완료 시간이 다를 수 있음. 시간에 민감하지 않은 작업에 적합함
    - 야간 배치 ETL 작업, 주말 작업, 일회성 대량 데이터 모으기 작업 등
- IAM Role: `AWSGlueServiceRole`
  - EC2, S3, Cloudwatch Logs를 포함한 관련 서비스에 대한 액세스를 허용하는 AWS Glue 서비스 역할에 대한 정책
  - AWS의 관리형 정책이다

# AWS Lake Formation

https://docs.aws.amazon.com/ko_kr/lake-formation/latest/dg/what-is-lake-formation.html

- Lake Formation은 데이터 거버넌스 및 엑세스 제어를 효율적으로 관리하는 서비스
  - 데이터 거버넌스란?
    - 데이터의 보안, 개인정보 보호, 정확성, 가용성, 사용성을 보장하기 위해 수행하는 모든 작업
- 데이터 레이크에 등록된 모든 데이터의 엑세스 권한 관리
  - S3, Glue, Athena, Redshift, EMR, QuickSight, DataBrew, IAM, KMS, CloudTrail

# AWS Redshift

- 완전관리형 데이터 웨어하우스
- 데이터를 빠르게 분석 할 수 있도록 설계됨. 고성능, 저비용, 확장성이 장점임.
- TB, PB 단위의 빅데이터를 초고속으로 쿼리할 수 있음

# Amazon Managed Service for Apache Flink

https://docs.aws.amazon.com/ko_kr/managed-flink/latest/java/what-is.html

- 구: Amazon Kinesis Data Analytics
- 실시간 스트리밍 데이터를 처리하는 AWS의 완전관리형 서비스
- **Apache Flink란?**
  - 분산 스트리밍 데이터 처리를 위한 오픈소스 프레임워크
- Flink를 직접 설치/운영할 필요 없이 AWS에서 인프라를 자동으로 관리함.
- 실시간 데이터 처리, ETL, 집계 및 분석 가능
- Kinesis, Kafka, S3, Timestream, Redshift 등과 연동 가능
- **실시간 데이터 스트리밍 처리가 필요할 때 사용**

# AWS S3

- S3 버켓에 이벤트를 생성할 수 있음.
  - 파일 업로드, 전송, 복사 등등 이벤트 알림 생성 가능
    ![스크린샷 2025-03-25 오전 12.12.16.png](attachment:d6d1d973-581b-4a0f-8b2c-1287f4c53041:스크린샷_2025-03-25_오전_12.12.16.png)
  - 이후 Lambda, SNS, SQS 등으로 트리거 가능
    ![스크린샷 2025-03-25 오전 12.12.48.png](attachment:504363fe-bf70-4bf3-a0d8-d446bc4d1765:스크린샷_2025-03-25_오전_12.12.48.png)

# 기타 잡지식

## Apache Parquet(아파치 파켓) 이란?

- Apache Parquet은 칼럼 지향(Columnar) 데이터 저장 형식으로, 대용량 데이터를 효율적으로 저장하고 빠르게 조회할 수 있도록 설계된 오픈소스 파일 포맷입니다.
- 대부분의 빅데이터 분석 플랫폼에서 지원함 (Athena, Redshift Spectrum, Spark, Hive 등)
- 일반적인 CSV나 JSON 같은 **로우 저장(Row-based)** 방식과 다르게, **Parquet은 열 단위로 데이터를 저장**
- 같은 열(Column)의 값이 유사한 경우가 많아 압축 효율이 뛰어남

## Snappy 압축 방식

- google이 개발한 블록기반 압축 방식
- 빠른 압축 및 해제 속도를 제공
- 다른 압축 알고리즘보다 압축률을 낮지만, 빠른 속도를 제공해서 데이터 분석, 로그 저장, DB 및 빅데이터 처리에서 많이 사용됨.
